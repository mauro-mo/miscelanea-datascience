{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import preprocessing\n",
    "\n",
    "df1 = pd.read_csv('craigslistVehicles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, quería explorar mis datos. Al ejecutar el siguiente código, pude determinar que había 550313 filas y 22 columnas. De las 20 variables, decidí comenzar con solo algunas características y agregar gradualmente más para evitar un ajuste excesivo. 'Precio' fue mi variable de predicción (y), y 'año', 'fabricante', 'odómetro', 'marca', 'transmisión', 'lat', 'largo', 'combustible' fueron mis características iniciales. Usando .describe (), me di cuenta de que el precio y los odómetros de algunas publicaciones no tenían sentido: algunas publicaciones tenían un precio de 1 más de 1,000,000,000, y algunas tenían un kilometraje de más de 1,000,000 km. Lo resolví creando un umbral para 'precio' y 'odómetro'. Por último, eliminé las filas con valores nulos en cualquiera de las características elegidas.\n",
    "\n",
    "(Nota: inicialmente comencé solo con 'año', 'fabricante' y 'odómetro', pero descubrí que agregar más variables mejoraba la precisión de mi modelo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['url', 'city', 'city_url', 'price', 'year', 'manufacturer', 'make',\n",
      "       'condition', 'cylinders', 'fuel', 'odometer', 'title_status',\n",
      "       'transmission', 'VIN', 'drive', 'size', 'type', 'paint_color',\n",
      "       'image_url', 'desc', 'lat', 'long'],\n",
      "      dtype='object')\n",
      "550313\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "### Explorar Datos ### \n",
    "print(df1.columns)   # Muestra encabezados de columnas\n",
    "print(len(df1.index)) # Muestra número de filas\n",
    "print(len(df1.columns)) # Muestra número de columnas \n",
    "\n",
    "### Limpieza/Preparación de Datos ### \n",
    "# 1. Establecer un precio piso y techo\n",
    "df1 = df1[df1['price'] < 99999.00]\n",
    "df1 = df1[df1['price'] > 999.99]\n",
    "\n",
    "# 2. Eliminar cualquier fila donde year esté en blanco o <1900\n",
    "df1 = df1[df1['year'] > 1900]\n",
    "df1 = df1.dropna(axis=0, subset=['year'])\n",
    "\n",
    "# 3. Eliminar cualquier fila donde manufacturer esté en blanco\n",
    "df1 = df1.dropna(axis=0, subset=['manufacturer'])\n",
    "\n",
    "# 4. Eliminar cualquier fila donde el odometer esté en blanco o <999,999\n",
    "df1 = df1.dropna(axis=0, subset=['odometer'])\n",
    "df1 = df1[df1['odometer'] < 899999.00]\n",
    "\n",
    "# 5. Eliminar cualquier fila donde make esté en blanco\n",
    "df1 = df1.dropna(axis=0, subset=['make'])\n",
    "\n",
    "# 6. Eliminar cualquier fila donde la transmission esté en blanco\n",
    "df1 = df1.dropna(axis=0, subset=['transmission'])\n",
    "\n",
    "# 7. Eliminar cualquier fila donde lat y long estén en blanco\n",
    "df1 = df1.dropna(axis=0, subset=['lat'])\n",
    "df1 = df1.dropna(axis=0, subset=['long'])\n",
    "\n",
    "# 8. Eliminar cualquier fila donde fuel esté en blanco\n",
    "df1 = df1.dropna(axis=0, subset=['fuel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelado de datos\n",
    "\n",
    "Decidí usar un modelo de bosque aleatorio porque los bosques aleatorios son muy versátiles y también he tenido experiencia previa implementando uno en KNIME. Además, usé LabelEncoder () para poder usar datos categóricos como parte de mis valores X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                      n_jobs=None, oob_score=False, random_state=1, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establecer el objetivo de predicción\n",
    "y = df1.price\n",
    "\n",
    "# Selección de características\n",
    "used_car_features = ['year', 'odometer', 'manufacturer', 'make', 'transmission','lat','long','fuel']\n",
    "X = df1[used_car_features]\n",
    "# Necesito convertir string a float\n",
    "le = preprocessing.LabelEncoder()\n",
    "X = X.apply(le.fit_transform)\n",
    "\n",
    "# Datos de entrenamiento y pruebas divididos\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Definir modelo\n",
    "used_car_model = RandomForestRegressor(random_state=1)\n",
    "\n",
    "# Fit modelo\n",
    "used_car_model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluación de datos \n",
    "\n",
    "A través de numerosas iteraciones de agregar más funciones (como se dijo antes), pude mejorar el error absoluto medio de 4375.07 a 1737. Como eso es todo! Con el tiempo, debería (con suerte) poder mejorar el MAE aún más."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1787.6984376484772\n",
      "14254.899043680107\n",
      "359294\n"
     ]
    }
   ],
   "source": [
    "### Evaluación de Datos ###\n",
    "val_predictions = used_car_model.predict(val_X)\n",
    "print(mean_absolute_error(val_y, val_predictions))\n",
    "print(df1['price'].mean())\n",
    "print(len(df1.index)) # Ver número de filas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
